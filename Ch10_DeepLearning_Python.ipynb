{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc378879",
   "metadata": {},
   "source": [
    "# Class Workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f1c117",
   "metadata": {},
   "source": [
    "## In class activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b9c178",
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib.pyplot import subplots\n",
    "#import statsmodels.api as sm\n",
    "from plotnine import *\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as sm\n",
    "#import ISLP as islp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd8f84d",
   "metadata": {},
   "source": [
    "### Ames Housing data\n",
    "\n",
    "\n",
    "Please take a look at the Ames Hoursing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7792c845",
   "metadata": {
    "Rmd_chunk_options": "echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ames_raw=pd.read_csv(\"ames_raw.csv\")\n",
    "ames_raw = ames_raw.select_dtypes(include=['int64', 'float64'])\n",
    "ames_raw = ames_raw.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbde9d19",
   "metadata": {},
   "source": [
    "Use data of `ames_raw` up to 2008 predict the housing price for the later years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcb9eca2",
   "metadata": {
    "Rmd_chunk_options": "echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ames_raw_2009, ames_raw_2008= ames_raw.query('`Yr Sold`>=2008').copy(), ames_raw.query('`Yr Sold` <2008').copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da715eb",
   "metadata": {},
   "source": [
    "Use the following loss function calculator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "145b46d4",
   "metadata": {
    "Rmd_chunk_options": "echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def calc_loss(prediction,actual):\n",
    "  difpred = actual-prediction\n",
    "  RMSE =pow(difpred.pow(2).mean(),1/2)\n",
    "  operation_loss=abs(sum(difpred[difpred<0]))+sum(0.1*actual[difpred>0])\n",
    "  return RMSE,operation_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7124297b",
   "metadata": {},
   "source": [
    "Use a simple neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1cd4b1f",
   "metadata": {
    "Rmd_chunk_options": "eval=FALSE,echo=show_code",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# nnfit_2008= # [\"your model here\"] # use ames_raw_2008\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "features = [\"MS SubClass\", \"Lot Frontage\", \"Lot Area\", \"Misc Val\", \"Mo Sold\"]\n",
    "\n",
    "ames_raw_2008 = ames_raw_2008.dropna(axis = 0, how=\"any\", subset=features)\n",
    "\n",
    "\n",
    "X = ames_raw_2008[features].to_numpy()\n",
    "y = ames_raw_2008[\"SalePrice\"].to_numpy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X)\n",
    "X_tensor = torch.from_numpy(X_train).float()\n",
    "y_tensor = torch.from_numpy(y).float()\n",
    "\n",
    "dataset =  TensorDataset(X_tensor, y_tensor)\n",
    "# dataloader = DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "# model = LinearRegression()\n",
    "\n",
    "class nnModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(nnModel, self).__init__()\n",
    "        # self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(5, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(20, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = self.flatten(x)\n",
    "        return self.sequential(x)\n",
    "\n",
    "\n",
    "model = nnModel()\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = RMSprop(model.parameters(), lr=0.01)\n",
    "model.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    for input, target in dataset:\n",
    "        optimizer.zero_grad()\n",
    "        # print(input)\n",
    "        output = model(input).squeeze()\n",
    "\n",
    "        # RMSE,operation_loss = calc_loss(output, target)\n",
    "        # loss = RMSE*500 + operation_loss\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(loss)\n",
    "        # print(output.shape)\n",
    "        # print(target.shape)\n",
    "        # print(output)\n",
    "        # print(target)\n",
    "        \n",
    "\n",
    "nnfit_2008 = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75bbd37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1319, 37)\n",
      "(1319,)\n"
     ]
    }
   ],
   "source": [
    "X_test = ames_raw_2009[features].values\n",
    "X_test = scaler.transform(X_test)\n",
    "X_test_tensor = torch.from_numpy(X_test).float()\n",
    "nnfit_2008.eval()\n",
    "pred_2009 = nnfit_2008(X_test_tensor).squeeze() # Predict using ames_raw_2009\n",
    "\n",
    "pred_2009 = pred_2009.detach().numpy()\n",
    "print(pred_2009[:5])\n",
    "print(ames_raw_2009.SalePrice[:5])\n",
    "print(calc_loss(pred_2009,ames_raw_2009.SalePrice))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90018571",
   "metadata": {},
   "source": [
    "When you decide on your model use the following to come up with your test loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45d1e7",
   "metadata": {},
   "source": [
    "Try to answer the following additional questions.\n",
    "\n",
    "- Does your model indicate a good fit?\n",
    "\n",
    "\n",
    "- How does your model result compare to the previous models you fit?\n",
    "\n",
    "\n",
    "- Can you explain what feature was important determinant of the price?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cf9dd0",
   "metadata": {},
   "source": [
    "### COVID 19 Survival in Mexico\n",
    "\n",
    "Let's revisit COVID-19 in Mexico dataset from the [Mexican government](https://datos.gob.mx/busca/dataset/informacion-referente-a-casos-covid-19-en-mexico).  This data is a version downloaded from [Kaggle](https://www.kaggle.com/datasets/meirnizri/covid19-dataset?resource=download).  The raw dataset consists of 21 unique features and 1,048,576 unique patients. In the Boolean features, 1 means \"yes\" and 2 means \"no\". values as 97 and 99 are missing data.\n",
    "\n",
    "- sex: 1 for female and 2 for male.\n",
    "- age: of the patient.\n",
    "- classification: COVID test findings. Values 1-3 mean that the patient was diagnosed with COVID in different degrees. 4 or higher means that the patient is not a carrier of COVID or that the test is inconclusive.\n",
    "- patient type: type of care the patient received in the unit. 1 for returned home and 2 for hospitalization.\n",
    "- pneumonia: whether the patient already have air sacs inflammation or not.\n",
    "- pregnancy: whether the patient is pregnant or not.\n",
    "- diabetes: whether the patient has diabetes or not.\n",
    "- copd: Indicates whether the patient has Chronic obstructive pulmonary disease or not.\n",
    "- asthma: whether the patient has asthma or not.\n",
    "- inmsupr: whether the patient is immunosuppressed or not.\n",
    "- hypertension: whether the patient has hypertension or not.\n",
    "- cardiovascular: whether the patient has heart or blood vessels related disease.\n",
    "- renal chronic: whether the patient has chronic renal disease or not.\n",
    "- other disease: whether the patient has other disease or not.\n",
    "- obesity: whether the patient is obese or not.\n",
    "- tobacco: whether the patient is a tobacco user.\n",
    "- usmr: Indicates whether the patient treated medical units of the first, second or third level.\n",
    "- medical unit: type of institution of the National Health System that provided the care.\n",
    "- intubed: whether the patient was connected to the ventilator.\n",
    "- icu: Indicates whether the patient had been admitted to an Intensive Care Unit.\n",
    "- date died: If the patient died indicate the date of death, and 9999-99-99 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeef41dc",
   "metadata": {
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "Train_COVID= pd.read_csv('Train_COVID.zip',compression='zip')\n",
    "Test_COVID= pd.read_csv('Test_COVID.zip',compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9846d1",
   "metadata": {},
   "source": [
    "- Fit a sequence model that predicts the number of cases a week a head.\n",
    "\n",
    "- Modify your model to make prediction for different gender.\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea2ddbc",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/f6hz6yyx4m5_t7__6mnw1b6r0000gn/T/ipykernel_71197/2847834208.py:8: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "/var/folders/k3/f6hz6yyx4m5_t7__6mnw1b6r0000gn/T/ipykernel_71197/2847834208.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "98/98 - 1s - loss: 0.0497 - 603ms/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "98/98 - 0s - loss: 0.0363 - 50ms/epoch - 506us/step\n",
      "Epoch 3/10\n",
      "98/98 - 0s - loss: 0.0293 - 51ms/epoch - 516us/step\n",
      "Epoch 4/10\n",
      "98/98 - 0s - loss: 0.0287 - 50ms/epoch - 509us/step\n",
      "Epoch 5/10\n",
      "98/98 - 0s - loss: 0.0310 - 50ms/epoch - 514us/step\n",
      "Epoch 6/10\n",
      "98/98 - 0s - loss: 0.0282 - 50ms/epoch - 512us/step\n",
      "Epoch 7/10\n",
      "98/98 - 0s - loss: 0.0279 - 49ms/epoch - 499us/step\n",
      "Epoch 8/10\n",
      "98/98 - 0s - loss: 0.0276 - 50ms/epoch - 507us/step\n",
      "Epoch 9/10\n",
      "98/98 - 0s - loss: 0.0285 - 49ms/epoch - 500us/step\n",
      "Epoch 10/10\n",
      "98/98 - 0s - loss: 0.0280 - 49ms/epoch - 497us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28f93e650>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def preprocess_data(data, look_back=1):\n",
    "    data = data[data['CLASIFFICATION_FINAL'] <= 3]  # Filter confirmed cases\n",
    "    data['DATE_DIED'] = pd.to_datetime(data['DATE_DIED'], errors='coerce')  # Assuming there's a 'date' column\n",
    "    data = data.set_index('DATE_DIED').resample('W').count()['CLASIFFICATION_FINAL']  # Weekly counts\n",
    "    data = np.array(data).reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data = scaler.fit_transform(data)\n",
    "    \n",
    "    # Create dataset for sequence prediction\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data) - look_back):\n",
    "        X.append(data[i:(i + look_back), 0])\n",
    "        Y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "look_back = 3  # Using last 3 weeks' data to predict the next week\n",
    "X_train, y_train = preprocess_data(Train_COVID, look_back)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "# Building the LSTM Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(look_back, 1)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ed35c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k3/f6hz6yyx4m5_t7__6mnw1b6r0000gn/T/ipykernel_71197/2847834208.py:8: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "/var/folders/k3/f6hz6yyx4m5_t7__6mnw1b6r0000gn/T/ipykernel_71197/2847834208.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = preprocess_data(Test_COVID, look_back)\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63065e78",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db356786",
   "metadata": {},
   "source": [
    "## Problem set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc2c5a9",
   "metadata": {},
   "source": [
    "### Writing your own gradient decent\n",
    "\n",
    "Consider the simple function $R(\\beta) = sin(\\beta) + \\beta/10$.\n",
    "\n",
    "(a) Draw a graph of this function over the range $\\beta \\in [−6, 6]$.\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683d706",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8788e2b3",
   "metadata": {},
   "source": [
    "(b) What is the derivative of this function?\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac6932c",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b581c379",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "(c) Given $\\beta_0 = 2.3$, run gradient descent to find a local minimum of $R(\\beat)$ using a learning rate of $\\rho= 0.1$. Show each of $\\beta_0,\\beta_1,\\dots$ in your plot, as well as the final answer.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c9f93f",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3134f645",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "(d) Repeat with $\\beta_0 = 1.4$.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efea5a0",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b33b24",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e73f6ae",
   "metadata": {},
   "source": [
    "### Default\n",
    "\n",
    "Fit a neural network to the Default data. Use a single hidden layer with 10 units, and dropout regularization. Have a look at Labs 10.9.1–10.9.2 for guidance. Compare the classification performance of your model with that of linear logistic regression.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f15d9d3",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fb5727",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d06410",
   "metadata": {},
   "source": [
    "### IMDb\n",
    "\n",
    "Repeat the analysis of Lab 10.9.5 on the IMDb data using a similarly structured neural network. We used 16 hidden units at each of two hidden layers. Explore the effect of increasing this to 32 and 64 units per layer, with and without 30% dropout regularization.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1d63690",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import ISLP as islp\n",
    "from ISLP.torch.imdb import (load_lookup,\n",
    "                             load_tensor,\n",
    "                             load_sparse,\n",
    "                             load_sequential)\n",
    "from ISLP.torch import (SimpleDataModule,\n",
    "                        SimpleModule,\n",
    "                        ErrorTracker,\n",
    "                        rec_num_workers)\n",
    "from torchinfo import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1651ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(imdb_seq_train,\n",
    " imdb_seq_test) = load_sequential(root='data/IMDB')\n",
    "padded_sample = np.asarray(imdb_seq_train.tensors[0][0])\n",
    "sample_review = padded_sample[padded_sample > 0][:12]\n",
    "sample_review[:12]\n",
    "lookup = load_lookup(root='data/IMDB')\n",
    "' '.join(lookup[i] for i in sample_review)\n",
    "max_num_workers=10\n",
    "(imdb_train,\n",
    " imdb_test) = load_tensor(root='data/IMDB')\n",
    "imdb_dm = SimpleDataModule(imdb_train,\n",
    "                           imdb_test,\n",
    "                           validation=2000,\n",
    "                           num_workers=min(6, max_num_workers),\n",
    "                           batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92ff5445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(IMDBModel, self).__init__()\n",
    "        self.dense1 = nn.Linear(input_size, 32)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(32, 32)\n",
    "        self.output = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        val = x\n",
    "        for _map in [self.dense1,\n",
    "                     self.activation,\n",
    "                     self.dense2,\n",
    "                     self.activation,\n",
    "                     self.output]:\n",
    "            val = _map(val)\n",
    "        return torch.flatten(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ae4b1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "IMDBModel                                [25000, 10003]            [25000]                   --\n",
       "├─Linear: 1-1                            [25000, 10003]            [25000, 32]               320,128\n",
       "├─ReLU: 1-2                              [25000, 32]               [25000, 32]               --\n",
       "├─Linear: 1-3                            [25000, 32]               [25000, 32]               1,056\n",
       "├─ReLU: 1-4                              [25000, 32]               [25000, 32]               --\n",
       "├─Linear: 1-5                            [25000, 32]               [25000, 1]                33\n",
       "===================================================================================================================\n",
       "Total params: 321,217\n",
       "Trainable params: 321,217\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 8.03\n",
       "===================================================================================================================\n",
       "Input size (MB): 1000.30\n",
       "Forward/backward pass size (MB): 13.00\n",
       "Params size (MB): 1.28\n",
       "Estimated Total Size (MB): 1014.58\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_model = IMDBModel(imdb_test.tensors[0].size()[1])\n",
    "summary(imdb_model,\n",
    "        input_size=imdb_test.tensors[0].size(),\n",
    "        col_names=['input_size',\n",
    "                   'output_size',\n",
    "                   'num_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55f90bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBModel(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(IMDBModel, self).__init__()\n",
    "        self.dense1 = nn.Linear(input_size, 64)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(64, 64)\n",
    "        self.output = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        val = x\n",
    "        for _map in [self.dense1,\n",
    "                     self.activation,\n",
    "                     self.dense2,\n",
    "                     self.activation,\n",
    "                     self.output]:\n",
    "            val = _map(val)\n",
    "        return torch.flatten(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dda61419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "IMDBModel                                [25000, 10003]            [25000]                   --\n",
       "├─Linear: 1-1                            [25000, 10003]            [25000, 64]               640,256\n",
       "├─ReLU: 1-2                              [25000, 64]               [25000, 64]               --\n",
       "├─Linear: 1-3                            [25000, 64]               [25000, 64]               4,160\n",
       "├─ReLU: 1-4                              [25000, 64]               [25000, 64]               --\n",
       "├─Linear: 1-5                            [25000, 64]               [25000, 1]                65\n",
       "===================================================================================================================\n",
       "Total params: 644,481\n",
       "Trainable params: 644,481\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 16.11\n",
       "===================================================================================================================\n",
       "Input size (MB): 1000.30\n",
       "Forward/backward pass size (MB): 25.80\n",
       "Params size (MB): 2.58\n",
       "Estimated Total Size (MB): 1028.68\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_model = IMDBModel(imdb_test.tensors[0].size()[1])\n",
    "summary(imdb_model,\n",
    "        input_size=imdb_test.tensors[0].size(),\n",
    "        col_names=['input_size',\n",
    "                   'output_size',\n",
    "                   'num_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b61f2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "~~~\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e719c",
   "metadata": {},
   "source": [
    "### NYSE\n",
    "\n",
    "Fit a lag-5 autoregressive model to the NYSE data, as described in the text and Lab 10.9.6. Refit the model with a 12-level factor representing the month. Does this factor improve the performance of the model?\n",
    "\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d537a6d2",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45633025715446285"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ISLP import load_data\n",
    "NYSE = load_data('NYSE')\n",
    "cols = ['DJ_return', 'log_volume', 'log_volatility']\n",
    "X = pd.DataFrame(StandardScaler(\n",
    "                     with_mean=True,\n",
    "                     with_std=True).fit_transform(NYSE[cols]),\n",
    "                 columns=NYSE[cols].columns,\n",
    "                 index=NYSE.index)\n",
    "for lag in range(1, 6):\n",
    "    for col in cols:\n",
    "        newcol = np.zeros(X.shape[0]) * np.nan\n",
    "        newcol[lag:] = X[col].values[:-lag]\n",
    "        X.insert(len(X.columns), \"{0}_{1}\".format(col, lag), newcol)\n",
    "X.insert(len(X.columns), 'train', NYSE['train'])\n",
    "X = X.dropna()\n",
    "Y, train = X['log_volume'], X['train']\n",
    "X = X.drop(columns=['train'] + cols)\n",
    "X.columns\n",
    "M = LinearRegression()\n",
    "M.fit(X[train], Y[train])\n",
    "M.score(X[~train], Y[~train])\n",
    "X_day = pd.merge(X, \n",
    "                 pd.get_dummies(NYSE['day_of_week']),\n",
    "                 on='date')\n",
    "M.fit(X_day[train], Y[train])\n",
    "M.score(X_day[~train], Y[~train])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82790743",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a79190c",
   "metadata": {},
   "source": [
    "### NYSE 2\n",
    "In Section 10.9.6, we showed how to fit a linear AR model to the\n",
    "NYSE data using the `LinearRegression()` function. However, we also\n",
    "mentioned that we can “flatten” the short sequences produced for\n",
    "the RNN model in order to fit a linear AR model. Use this latter\n",
    "approach to fit a linear AR model to the NYSE data. Compare the test\n",
    "R2 of this linear AR model to that of the linear AR model that we fit\n",
    "in the lab. What are the advantages/disadvantages of each approach?\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9b49f2e",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "ordered_cols = []\n",
    "for lag in range(5,0,-1):\n",
    "    for col in cols:\n",
    "        ordered_cols.append('{0}_{1}'.format(col, lag))\n",
    "X = X.reindex(columns=ordered_cols)\n",
    "X.columns\n",
    "X_rnn = X.to_numpy().reshape((-1,5,3))\n",
    "X_rnn.shape\n",
    "class NYSEModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NYSEModel, self).__init__()\n",
    "        self.rnn = nn.RNN(3,\n",
    "                          12,\n",
    "                          batch_first=True)\n",
    "        self.dense = nn.Linear(12, 1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "    def forward(self, x):\n",
    "        val, h_n = self.rnn(x)\n",
    "        val = self.dense(self.dropout(val[:,-1]))\n",
    "        return torch.flatten(val)\n",
    "nyse_model = NYSEModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6280465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #\n",
       "===================================================================================================================\n",
       "NYSEModel                                [1770, 5, 3]              [1770]                    --\n",
       "├─RNN: 1-1                               [1770, 5, 3]              [1770, 5, 12]             204\n",
       "├─Dropout: 1-2                           [1770, 12]                [1770, 12]                --\n",
       "├─Linear: 1-3                            [1770, 12]                [1770, 1]                 13\n",
       "===================================================================================================================\n",
       "Total params: 217\n",
       "Trainable params: 217\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 1.83\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.11\n",
       "Forward/backward pass size (MB): 0.86\n",
       "Params size (MB): 0.00\n",
       "Estimated Total Size (MB): 0.97\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = []\n",
    "for mask in [train, ~train]:\n",
    "    X_rnn_t = torch.tensor(X_rnn[mask].astype(np.float32))\n",
    "    Y_t = torch.tensor(Y[mask].astype(np.float32))\n",
    "    datasets.append(TensorDataset(X_rnn_t, Y_t))\n",
    "nyse_train, nyse_test = datasets\n",
    "summary(nyse_model,\n",
    "        input_data=X_rnn_t,\n",
    "        col_names=['input_size',\n",
    "                   'output_size',\n",
    "                   'num_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff6f42d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Repeat the previous exercise, but now fit a nonlinear AR model by\n",
    "“flattening” the short sequences produced for the RNN model.\n",
    "\n",
    " Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7f0a120",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64]) torch.Size([64])\n",
      "torch.Size([64]) torch.Size([64])\n",
      "torch.Size([64]) torch.Size([64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /Users/chenxuanxiong/github-classroom/BU-MSSP-Classroom/MA679_Spring2024_10_deep_learning-SwaineXiong/lightning_logs\n",
      "\n",
      "  | Name  | Type             | Params\n",
      "-------------------------------------------\n",
      "0 | model | NonLinearARModel | 705   \n",
      "1 | loss  | MSELoss          | 0     \n",
      "-------------------------------------------\n",
      "705       Trainable params\n",
      "0         Non-trainable params\n",
      "705       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca54e609e35f43e2b2e166972f2ed26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from torchmetrics import (MeanAbsoluteError,\n",
    "                          R2Score)\n",
    "from pytorch_lightning import Trainer\n",
    "class NonLinearARModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NonLinearARModel, self).__init__()\n",
    "        self._forward = nn.Sequential(nn.Flatten(),\n",
    "                                      nn.Linear(20, 32),\n",
    "                                      nn.ReLU(),\n",
    "                                      nn.Dropout(0.5),\n",
    "                                      nn.Linear(32, 1))\n",
    "    def forward(self, x):\n",
    "        return torch.flatten(self._forward(x))\n",
    "\n",
    "nl_model = NonLinearARModel()\n",
    "nl_optimizer = RMSprop(nl_model.parameters(),\n",
    "                           lr=0.001)\n",
    "nl_module = SimpleModule.regression(nl_model,\n",
    "                                        optimizer=nl_optimizer,\n",
    "                                        metrics={'r2':R2Score()})\n",
    "nyse_dm = SimpleDataModule(nyse_train,\n",
    "                           nyse_test,\n",
    "                           num_workers=min(4, max_num_workers),\n",
    "                           validation=nyse_test,\n",
    "                           batch_size=64)\n",
    "for idx, (x, y) in enumerate(nyse_dm.train_dataloader()):\n",
    "    out = nyse_model(x)\n",
    "    print(y.size(), out.size())\n",
    "    if idx >= 2:\n",
    "        break\n",
    "nyse_trainer = Trainer(deterministic=True,\n",
    "                       max_epochs=200,\n",
    "                       callbacks=[ErrorTracker()])\n",
    "nyse_trainer.fit(nl_module,\n",
    "                 datamodule=nyse_dm)\n",
    "nyse_trainer.test(nl_module,\n",
    "                  datamodule=nyse_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e5e731",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018aaf64",
   "metadata": {},
   "source": [
    "### NYSE 3\n",
    "\n",
    "Consider the RNN fit to the NYSE data in Section 10.9.6. Modify the code to allow inclusion of the variable day_of_week, and fit the RNN. Compute the test $R^2$.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d3d82",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce0591",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d647a4b",
   "metadata": {},
   "source": [
    "### CNN on photo\n",
    "\n",
    "From your collection of personal photographs, pick 10 images of animals\n",
    "(such as dogs, cats, birds, farm animals, etc.). If the subject\n",
    "does not occupy a reasonable part of the image, then crop the image.\n",
    "Now use a pretrained image classification CNN as in Lab 10.9.4 to\n",
    "predict the class of each of your images, and report the probabilities\n",
    "for the top five predicted classes for each image.\n",
    "\n",
    "Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c81612",
   "metadata": {
    "Rmd_chunk_options": "echo=TRUE",
    "kernel": "Python3",
    "tags": [
     "report_cell"
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d56a27",
   "metadata": {},
   "source": [
    "Your answer:\n",
    "\n",
    "~~~\n",
    "Please write your answer in full sentences.\n",
    "\n",
    "\n",
    "~~~"
   ]
  }
 ],
 "metadata": {
  "Rmd_chunk_options": {
   "author": "Your Name",
   "date": "2022-12-21",
   "output": "github_document",
   "title": "Deep Learning"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ],
    [
     "R",
     "ir",
     "",
     ""
    ],
    [
     "css",
     "css",
     "",
     ""
    ],
    [
     "Python3",
     "ir",
     "",
     ""
    ]
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
